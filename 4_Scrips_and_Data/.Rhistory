result_df <- bind_rows(result_df, result)
timeline_Test <- rbind(timeline_Test, new_row)
# Move 1 hour forward
CurrentTime <- CurrentTime + hours(1)
}
timeline_Test
# Author:
# Juan Bettinelli,
# Script to be used in the Paper "Quantification of methane emissions in Hamburg using a network of FTIR spectrometers and an inverse modeling approach"
# Data from the Hamburg campaign 2021-2022.
# This Script is used for a Keeling analysed of the data collected in Hamburg Geomatikum in 2021.
# The script produces a timeline of the total Methan concentration
#Last edit: 22.05.2023
# Declare librarys used
library(ggplot2)
library(hexbin)
library(gridExtra)
library(dplyr)
library(plotly)
library(rio)
library(gridExtra)
library(grid)
library(pracma)
library(patchwork)
# library(ggplot2)
# library(hexbin)
# library(dplyr)
library(lubridate)
library(plotly)
library(rio)
library(cowplot)
#------------------------------------------------------------------
# Function to perform calculations on selected rows
Keeling_Caluclation <- function(TotalData, start_time, H = 12) {
# Select rows within the first 12 hours
# selected_rows <- TotalData %>%
#   filter(between(DateTime, start_time, start_time + hours(12)))
TotalData <- TotalData[complete.cases(TotalData[ , "X.CH4."]),c("UTC", "X.CH4.", "d13C.VPDB", "c13C", "d2H.VPDB", "c2H")]
SelectedData <- filter(TotalData, TotalData$UTC >= start_time & TotalData$UTC < start_time + hours(H), .preserve = FALSE)
if ((nrow(SelectedData[complete.cases(SelectedData[ , "d13C.VPDB"]),]) > 10) & (nrow(SelectedData[complete.cases(SelectedData[ , "d2H.VPDB"]),]) > 10)){
# Keeling Analyse for total data of the champagne Time series
# For C13
c13C_Line <- lm(d13C.VPDB ~ c13C, SelectedData )
c13C_coef <- coef(summary(c13C_Line))[, "Estimate"]
c13C_se <- coef(summary(c13C_Line))[, "Std. Error"]
# For H2
c2H_Line <- lm(d2H.VPDB ~ c2H, SelectedData )
c2H_coef <- coef(summary(c2H_Line))[, "Estimate"]
c2H_se <- coef(summary(c2H_Line))[, "Std. Error"]
result <- data.frame(UTC = start_time, c13C_coef = c13C_coef[[1]], c2H_coef = c2H_coef[[1]])
return(result)
}
else{
result <- data.frame(UTC = start_time, c13C_coef = NA, c2H_coef = NA)
return(result)
}
}
#------------------------------------------------------------------
# Function to perform calculations on selected rows
Keeling_Caluclation_Empa <- function(EMPA_csv, start_time, H = 12) {
# Select rows within the first 12 hours
# selected_rows <- TotalData %>%
#   filter(between(DateTime, start_time, start_time + hours(12)))
EMPA_csv <- EMPA_csv[complete.cases(EMPA_csv[ , "CH4"]),c("dtm.end", "CH4", "d13C_CH4", "c13C", "dD_CH4", "c2H")]
SelectedData <- filter(EMPA_csv, EMPA_csv$dtm.end > start_time & EMPA_csv$dtm.end < start_time + hours(H), .preserve = FALSE)
if ((nrow(SelectedData[complete.cases(SelectedData[ , "d13C_CH4"]),]) > 10) & (nrow(SelectedData[complete.cases(SelectedData[ , "dD_CH4"]),]) > 10)){
# Keeling Analyse for total data of the champagne Time series
# For C13
c13C_Line_EMPA <- lm(d13C_CH4 ~ c13C, SelectedData )
c13C_coef_EMPA <- coef(summary(c13C_Line_EMPA))[, "Estimate"]
c13C_se_EMPA <- coef(summary(c13C_Line_EMPA))[, "Std. Error"]
# For H2
c2H_Line_EMPA <- lm(dD_CH4 ~ c2H, SelectedData)
c2H_coef_EMPA <- coef(summary(c2H_Line_EMPA))[, "Estimate"]
c2H_se_EMPA <- coef(summary(c2H_Line_EMPA))[, "Std. Error"]
result <- data.frame(dtm.end = start_time, c13C_coef_EMPA = c13C_coef_EMPA[[1]], c2H_coef_EMPA = c2H_coef_EMPA[[1]])
return(result)
}
else{
result <- data.frame(dtm.end = start_time, c13C_coef_EMPA = NA, c2H_coef_EMPA = NA)
return(result)
}
}
#------------------------------------------------------------------
# Set Working Directory
setwd("/Users/juanbettinelli/Documents/Uni/MasterThesis/4_Scrips_and_Data")
# Set Starting and Finish Time
StartTime <- as.POSIXct('2021-08-01 22:03:00',
format = "%Y-%m-%d %H:%M:%S",
tz ="utc")
# Start Time: 2021-08-01 22:03:00
FinishTime <- as.POSIXct('2022-03-29 00:00:00',
format = "%Y-%m-%d %H:%M:%S",
tz ="utc")
# Total Timeseries: 2022-03-29 00:00:00
# Hamburg Campagne Timeseries: 2021-09-06 00:00:00
# Hamburg Campaine #2: 2021-09-17 10:21:00
########### Read the CSV File #############
# Read the CSV File
TotalData <- import("4_Data/OutputData/CombineMeteorologicalData.csv")
# format the Date 'UTC'
TotalData$UTC <- as.POSIXct(as.character(TotalData$UTC),
format = "%Y-%m-%d %H:%M:%S",
tz = "UTC")
# Convert the format of 'X.CH4.' to numeric
TotalData$X.CH4. <- as.numeric(TotalData$X.CH4.)
# Filter out all the dated that are outside the selected Strating and Finish time of the campaign
TotalData <- filter(TotalData, TotalData$UTC > StartTime & TotalData$UTC < FinishTime, .preserve = FALSE)
# Remove Empty Cells n data frame
TotalData <- TotalData[!is.na(TotalData$UTC),]
# Calculate 1/Mole Fraction for C13 & H2
TotalData$c13C <- 1/TotalData$X.CH4..13C
TotalData$c2H <- 1/TotalData$X.CH4..2H
EMPA_csv <- import("4_Data/9_EMPA/ts_sim_concDelta_HH_GEO_IFS_FP-C1.csv")
# format the Date 'UTC'
EMPA_csv$dtm.end <- as.POSIXct(as.character(EMPA_csv$dtm.end),
format = "%Y-%m-%d %H:%M:%S",
tz = "UTC")
# Convert the format of 'X.CH4.' to numeric
EMPA_csv$CH4 <- as.numeric(EMPA_csv$CH4)
# Filter out all the dated that are outside the selected Strating and Finish time of the campaign
EMPA_csv <- filter(EMPA_csv, EMPA_csv$dtm.end > StartTime & EMPA_csv$dtm.end < FinishTime, .preserve = FALSE)
# Remove Empty Cells n data frame
EMPA_csv <- EMPA_csv[!is.na(EMPA_csv$dtm.end),]
# Calculate 1/Mole Fraction for C13 & H2
EMPA_csv$c13C <- 1/EMPA_csv$CH4
EMPA_csv$c2H <- 1/EMPA_csv$CH4
################ Keeling analyse ##############
# Moving window in Hours
H <- 12
result_df <- data.frame(UTC = as.POSIXct(character()), c13C_coef = numeric(), c2H_coef = numeric())
CurrentTime <- StartTime
timeline_Test <- data.frame()
while (CurrentTime < FinishTime) {
# Call the function to perform calculations and append to the result dataframe
result <- Keeling_Caluclation(TotalData, CurrentTime, H)
result_df <- bind_rows(result_df, result)
timeline_Test <- rbind(timeline_Test, result)
# Move 1 hour forward
CurrentTime <- CurrentTime + hours(1)
}
timeline_Test
plot(timeline_Test)
source("~/Documents/Uni/MasterThesis/4_Scrips_and_Data/3_Scripts/Moving_Keeling_Plot.R", echo=TRUE)
source("~/Documents/Uni/MasterThesis/4_Scrips_and_Data/3_Scripts/Moving_Keeling_Plot.R", echo=TRUE)
source("~/Documents/Uni/MasterThesis/4_Scrips_and_Data/3_Scripts/Moving_Keeling_Plot.R", echo=TRUE)
source("~/Documents/Uni/MasterThesis/4_Scrips_and_Data/3_Scripts/Moving_Keeling_Plot.R", echo=TRUE)
# Create the Timeline plot
CH4_TL <- ggplot(TotalData[, ],
aes(x = UTC,
y = X.CH4.)) +
geom_line(color = "blue") +
labs(
y = expression("CH"[4]*" con. [ppb]")) +
scale_x_datetime(date_breaks = "15 day",
date_labels = "%d-%b") + # , limit=c(as.POSIXct(StartTime),as.POSIXct(FinishTime))
geom_line(data = EMPA_csv,
aes(x = dtm.end,
y = CH4*1),
col = "red") +
# scale_y_continuous(sec.axis = sec_axis(trans = ~./1,
#                                        name="EMPA"))+
theme(axis.text.x=element_blank(),
axis.title.x=element_blank(),
axis.ticks.x = element_blank(),
strip.text.x = element_blank(),
legend.position="none")
CH4_TL
TotalData$X.CH4.
TotalData_Plotting <- TotalData[complete.cases(TotalData[ , "X.CH4."]),c("UTC", "X.CH4.")]
# Create the Timeline plot
CH4_TL <- ggplot(TotalData_Plotting[, ],
aes(x = UTC,
y = X.CH4.)) +
geom_line(color = "blue") +
labs(
y = expression("CH"[4]*" con. [ppb]")) +
scale_x_datetime(date_breaks = "15 day",
date_labels = "%d-%b") + # , limit=c(as.POSIXct(StartTime),as.POSIXct(FinishTime))
geom_line(data = EMPA_csv,
aes(x = dtm.end,
y = CH4*1),
col = "red") +
# scale_y_continuous(sec.axis = sec_axis(trans = ~./1,
#                                        name="EMPA"))+
theme(axis.text.x=element_blank(),
axis.title.x=element_blank(),
axis.ticks.x = element_blank(),
strip.text.x = element_blank(),
legend.position="none")
CH4_TL
CH4_13C_TimeLine <- ggplot(MWK_Timeline[, ],
aes(x = UTC,
y = c13C_coef)) +
geom_line(color = "blue") +
labs(
y = expression("δ"^13*"C VPDB [‰]")) +
scale_x_datetime(date_breaks = "15 day",
date_labels = "%d-%b") + # , limit=c(as.POSIXct(StartTime),as.POSIXct(FinishTime))
geom_line(data = MWK_Timeline_EMPA,
aes(x = UTC,
y = c13C_coef*1),
col = "red") +
# scale_y_continuous(sec.axis = sec_axis(trans = ~./1,
#                                        name="EMPA"))+
theme(axis.text.x=element_blank(),
axis.title.x=element_blank(),
axis.ticks.x = element_blank(),
strip.text.x = element_blank(),
legend.position="none")
CH4_13C_TimeLine
View(MWK_Timeline)
View(MWK_Timeline_EMPA)
CH4_13C_TimeLine <- ggplot(MWK_Timeline[, ],
aes(x = UTC,
y = c13C_coef)) +
geom_line(color = "blue") +
labs(
y = expression("δ"^13*"C VPDB [‰]")) +
scale_x_datetime(date_breaks = "15 day",
date_labels = "%d-%b") + # , limit=c(as.POSIXct(StartTime),as.POSIXct(FinishTime))
geom_line(data = MWK_Timeline_EMPA,
aes(x = dtm.end,
y = c13C_coef*1),
col = "red") +
# scale_y_continuous(sec.axis = sec_axis(trans = ~./1,
#                                        name="EMPA"))+
theme(axis.text.x=element_blank(),
axis.title.x=element_blank(),
axis.ticks.x = element_blank(),
strip.text.x = element_blank(),
legend.position="none")
CH4_13C_TimeLine
CH4_13C_TimeLine <- ggplot(MWK_Timeline[, ],
aes(x = UTC,
y = c13C_coef)) +
geom_line(color = "blue") +
labs(
y = expression("δ"^13*"C VPDB [‰]")) +
scale_x_datetime(date_breaks = "15 day",
date_labels = "%d-%b") + # , limit=c(as.POSIXct(StartTime),as.POSIXct(FinishTime))
geom_line(data = MWK_Timeline_EMPA,
aes(x = dtm.end,
y = c13C_coef_EMPA*1),
col = "red") +
# scale_y_continuous(sec.axis = sec_axis(trans = ~./1,
#                                        name="EMPA"))+
theme(axis.text.x=element_blank(),
axis.title.x=element_blank(),
axis.ticks.x = element_blank(),
strip.text.x = element_blank(),
legend.position="none")
CH4_13C_TimeLine
CH4_2H_TimeLine <- ggplot(MWK_Timeline[, ],
aes(x = UTC,
y = c2H_coef)) +
geom_line(color = "blue") +
labs(x = "Fill Time [UTC]",
y = expression("δD VSMOW [‰]")) +
scale_x_datetime(date_breaks = "15 day",
date_labels = "%d-%b") + # , limit=c(as.POSIXct(StartTime),as.POSIXct(FinishTime))
geom_line(data = MWK_Timeline_EMPA,
aes(x = dtm.end,
y = c2H_coef_EMPA*1),
col = "red") +
# scale_y_continuous(sec.axis = sec_axis(trans = ~./1,
#                                        name="EMPA"))+
theme(axis.text.x=element_text(angle=60,
hjust=1),
axis.title.x=element_blank(),
strip.text.x = element_blank())
CH4_2H_TimeLine
Total_Timeline <- CH4_TL + CH4_13C_TimeLine + CH4_2H_TimeLine +
plot_layout(ncol = 1, guides = "collect")+
plot_annotation(
title = expression("MKP IRMS Measument and FLEXPART-COSMO Model, methane concentration, δ"^13*"C and δD"))+
theme(legend.position = "left", legend.box = "horizontal")
Total_Timeline
# Save the Plot
ggsave(paste0("24_MKP_EMPA_CH4_Isotope_Signature.png"),
Total_Timeline,
path = "4_Data/OutputData/Plots/24_EMPA",
width = 10,
height = 5)
# Author:
# Juan Bettinelli,
# Script to be used in the Paper "Quantification of methane emissions in Hamburg using a network of FTIR spectrometers and an inverse modeling approach"
# Data from the Hamburg campaign 2021-2022.
# This Script is used for a Keeling analysed of the data collected in Hamburg Geomatikum in 2021.
# The script produces a timeline of the total Methan concentration
#Last edit: 22.05.2023
# Declare librarys used
library(ggplot2)
library(hexbin)
library(gridExtra)
library(dplyr)
library(plotly)
library(rio)
library(gridExtra)
library(grid)
library(pracma)
library(patchwork)
# library(ggplot2)
# library(hexbin)
# library(dplyr)
library(lubridate)
library(plotly)
library(rio)
library(cowplot)
#------------------------------------------------------------------
# Calculate R-squared value
r_squared <- function(Total_CH4_Data, start_time, H = 12) {
SelectedData <- filter(Total_CH4_Data, Total_CH4_Data$UTC >= start_time & Total_CH4_Data$UTC < start_time + hours(H), .preserve = FALSE)
if ((nrow(SelectedData[complete.cases(SelectedData[ , "X.CH4."]),]) > (H-round(H*0.1))) & (nrow(SelectedData[complete.cases(SelectedData[ , "CH4"]),]) > (H-round(H*0.1)))){
correlation <- cor(SelectedData$X.CH4., SelectedData$CH4)
r_squared_value <- correlation^2
result <- data.frame(UTC = start_time, r_squared_value = r_squared_value)
return(result)
}
else{
result <- data.frame(UTC = start_time, r_squared_value = NA)
return(result)
}
}
#------------------------------------------------------------------
# Set Working Directory
setwd("/Users/juanbettinelli/Documents/Uni/MasterThesis/4_Scrips_and_Data")
# Set Starting and Finish Time
StartTime <- as.POSIXct('2021-08-01 23:00:00',
format = "%Y-%m-%d %H:%M:%S",
tz ="utc")
# Start Time: 2021-08-01 22:03:00
FinishTime <- as.POSIXct('2022-03-29 00:00:00',
format = "%Y-%m-%d %H:%M:%S",
tz ="utc")
# Total Timeseries: 2022-03-29 00:00:00
# Hamburg Campagne Timeseries: 2021-09-06 00:00:00
# Hamburg Campaine #2: 2021-09-17 10:21:00
########### Read the CSV File #############
# Read the CSV File
TotalData <- import("4_Data/OutputData/CombineMeteorologicalData.csv")
# format the Date 'UTC'
TotalData$UTC <- as.POSIXct(as.character(TotalData$UTC),
format = "%Y-%m-%d %H:%M:%S",
tz = "UTC")
# Convert the format of 'X.CH4.' to numeric
TotalData$X.CH4. <- as.numeric(TotalData$X.CH4.)
# Filter out all the dated that are outside the selected Strating and Finish time of the campaign
TotalData <- filter(TotalData, TotalData$UTC > StartTime & TotalData$UTC < FinishTime, .preserve = FALSE)
# Remove Empty Cells n data frame
TotalData <- TotalData[!is.na(TotalData$UTC),]
# Calculate 1/Mole Fraction for C13 & H2
TotalData$c13C <- 1/TotalData$X.CH4..13C
TotalData$c2H <- 1/TotalData$X.CH4..2H
EMPA_csv <- import("4_Data/9_EMPA/ts_sim_concDelta_HH_GEO_IFS_FP-C1.csv")
# format the Date 'UTC'
EMPA_csv$dtm.end <- as.POSIXct(as.character(EMPA_csv$dtm.end),
format = "%Y-%m-%d %H:%M:%S",
tz = "UTC")
# Convert the format of 'X.CH4.' to numeric
EMPA_csv$CH4 <- as.numeric(EMPA_csv$CH4)
# Filter out all the dated that are outside the selected Strating and Finish time of the campaign
EMPA_csv <- filter(EMPA_csv, EMPA_csv$dtm.end > StartTime & EMPA_csv$dtm.end < FinishTime, .preserve = FALSE)
# Remove Empty Cells n data frame
EMPA_csv <- EMPA_csv[!is.na(EMPA_csv$dtm.end),]
# Calculate 1/Mole Fraction for C13 & H2
EMPA_csv$c13C <- 1/EMPA_csv$CH4
EMPA_csv$c2H <- 1/EMPA_csv$CH4
Contribution_averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")])
Contribution_averages
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")])
Contribution_Percent <- Contribution_Averages/Contribution_Averages$CH4*100
Contribution_Averages
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")])
Contribution_Percent <- Contribution_Averages/colMeans(EMPA_csv[, "CH4"]) *100
Contribution_Averages <- as.data.frame(colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")]))
Contribution_Percent <- Contribution_Averages/colMeans(EMPA_csv[, "CH4"]) *100
Contribution_Averages
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")])
source("~/.active-rstudio-document", echo=TRUE)
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")])
Contribution_Averages_df <- data.frame(ColumnAverages = Contribution_Averages)
Contribution_Averages_df
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg", "CH4")])
Contribution_Averages_df <- data.frame(MeanContributions = Contribution_Averages)
Contribution_Averages_df
Contribution_Percent <- Contribution_Averages_df/Contribution_Averages_df["CH4", 2] *100
Contribution_Averages_df <- Contribution_Averages_df %>%
mutate(ColumnPercent = (CH4_energy + CH4_residential + CH4_industrial + CH4_natural_gas + CH4_transport + CH4_waste + CH4_agriculture + CH4_bg + CH4) / CH4 * 100)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg")])
Contribution_Averages_df <- data.frame(AverageContributions = Contribution_Averages)
Contribution_Averages_df$ColumnPercent <- (Contribution_Averages_df$AverageContributions / sum(Contribution_Averages_df$AverageContributions)) * 100
Contribution_Averages_df
Contribution_Averages_no_bg <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture")])
Contribution_Summery_no_bg <- data.frame(AverageContributions = Contribution_Averages_no_bg)
Contribution_Summery_no_bg$ColumnPercent <- (Contribution_Summery_no_bg$AverageContributions / sum(Contribution_Summery_no_bg$AverageContributions)) * 100
Contribution_Summery_no_bg
rowsum(Contribution_Summery_no_bg)
colsum(Contribution_Summery_no_bg)
colSums(Contribution_Summery_no_bg)
# Author:
# Juan Bettinelli,
# Script to be used in the Paper "Quantification of methane emissions in Hamburg using a network of FTIR spectrometers and an inverse modeling approach"
# Data from the Hamburg campaign 2021-2022.
# This Script is used for a Keeling analysed of the data collected in Hamburg Geomatikum in 2021.
# The script produces a timeline of the total Methan concentration
#Last edit: 22.05.2023
# Declare librarys used
library(ggplot2)
library(hexbin)
library(gridExtra)
library(dplyr)
library(plotly)
library(rio)
library(gridExtra)
library(grid)
library(pracma)
library(patchwork)
# library(ggplot2)
# library(hexbin)
# library(dplyr)
library(lubridate)
library(plotly)
library(rio)
library(cowplot)
#------------------------------------------------------------------
# Calculate R-squared value
r_squared <- function(Total_CH4_Data, start_time, H = 12) {
SelectedData <- filter(Total_CH4_Data, Total_CH4_Data$UTC >= start_time & Total_CH4_Data$UTC < start_time + hours(H), .preserve = FALSE)
if ((nrow(SelectedData[complete.cases(SelectedData[ , "X.CH4."]),]) > (H-round(H*0.1))) & (nrow(SelectedData[complete.cases(SelectedData[ , "CH4"]),]) > (H-round(H*0.1)))){
correlation <- cor(SelectedData$X.CH4., SelectedData$CH4)
r_squared_value <- correlation^2
result <- data.frame(UTC = start_time, r_squared_value = r_squared_value)
return(result)
}
else{
result <- data.frame(UTC = start_time, r_squared_value = NA)
return(result)
}
}
#------------------------------------------------------------------
# Set Working Directory
setwd("/Users/juanbettinelli/Documents/Uni/MasterThesis/4_Scrips_and_Data")
# Set Starting and Finish Time
StartTime <- as.POSIXct('2021-08-01 23:00:00',
format = "%Y-%m-%d %H:%M:%S",
tz ="utc")
# Start Time: 2021-08-01 22:03:00
FinishTime <- as.POSIXct('2022-03-29 00:00:00',
format = "%Y-%m-%d %H:%M:%S",
tz ="utc")
# Total Timeseries: 2022-03-29 00:00:00
# Hamburg Campagne Timeseries: 2021-09-06 00:00:00
# Hamburg Campaine #2: 2021-09-17 10:21:00
########### Read the CSV File #############
# Read the CSV File
TotalData <- import("4_Data/OutputData/CombineMeteorologicalData.csv")
# format the Date 'UTC'
TotalData$UTC <- as.POSIXct(as.character(TotalData$UTC),
format = "%Y-%m-%d %H:%M:%S",
tz = "UTC")
# Convert the format of 'X.CH4.' to numeric
TotalData$X.CH4. <- as.numeric(TotalData$X.CH4.)
# Filter out all the dated that are outside the selected Strating and Finish time of the campaign
TotalData <- filter(TotalData, TotalData$UTC > StartTime & TotalData$UTC < FinishTime, .preserve = FALSE)
# Remove Empty Cells n data frame
TotalData <- TotalData[!is.na(TotalData$UTC),]
# Calculate 1/Mole Fraction for C13 & H2
TotalData$c13C <- 1/TotalData$X.CH4..13C
TotalData$c2H <- 1/TotalData$X.CH4..2H
EMPA_csv <- import("4_Data/9_EMPA/ts_sim_concDelta_HH_GEO_IFS_FP-C1.csv")
# format the Date 'UTC'
EMPA_csv$dtm.end <- as.POSIXct(as.character(EMPA_csv$dtm.end),
format = "%Y-%m-%d %H:%M:%S",
tz = "UTC")
# Convert the format of 'X.CH4.' to numeric
EMPA_csv$CH4 <- as.numeric(EMPA_csv$CH4)
# Filter out all the dated that are outside the selected Strating and Finish time of the campaign
EMPA_csv <- filter(EMPA_csv, EMPA_csv$dtm.end > StartTime & EMPA_csv$dtm.end < FinishTime, .preserve = FALSE)
# Remove Empty Cells n data frame
EMPA_csv <- EMPA_csv[!is.na(EMPA_csv$dtm.end),]
# Calculate 1/Mole Fraction for C13 & H2
EMPA_csv$c13C <- 1/EMPA_csv$CH4
EMPA_csv$c2H <- 1/EMPA_csv$CH4
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg")])
Contribution_Summery <- data.frame(AverageContributions = Contribution_Averages)
Contribution_Summery$ColumnPercent <- (Contribution_Summery$AverageContributions / sum(Contribution_Summery$AverageContributions)) * 100
write.csv(Contribution_Summery, file = "4_Data/OutputData/Plots/24_EMPA/24_EMPA_CH4_Contribution_Summery.csv", row.names = TRUE)
Contribution_Averages_no_bg <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture")])
Contribution_Summery_no_bg <- data.frame(AverageContributions = Contribution_Averages_no_bg)
Contribution_Summery_no_bg$ColumnPercent <- (Contribution_Summery_no_bg$AverageContributions / sum(Contribution_Summery_no_bg$AverageContributions)) * 100
write.csv(Contribution_Summery_no_bg, file = "4_Data/OutputData/Plots/24_EMPA/24_EMPA_CH4_Contribution_Summery_no_bg.csv", row.names = TRUE)
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg")])
Contribution_Summery <- data.frame(AverageContributions = Contribution_Averages)
Contribution_Summery$ContributionPercent <- (Contribution_Summery$AverageContributions / sum(Contribution_Summery$AverageContributions)) * 100
write.csv(Contribution_Summery, file = "4_Data/OutputData/Plots/24_EMPA/24_EMPA_CH4_Contribution_Summery.csv", row.names = TRUE)
Contribution_Averages_no_bg <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture")])
Contribution_Summery_no_bg <- data.frame(AverageContributions = Contribution_Averages_no_bg)
Contribution_Summery_no_bg$ContributionPercent <- (Contribution_Summery_no_bg$AverageContributions / sum(Contribution_Summery_no_bg$AverageContributions)) * 100
write.csv(Contribution_Summery_no_bg, file = "4_Data/OutputData/Plots/24_EMPA/24_EMPA_CH4_Contribution_Summery_no_bg.csv", row.names = TRUE)
Contribution_Averages <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture", "CH4_bg")])
Contribution_Summery <- data.frame(AverageContributions = Contribution_Averages)
Contribution_Summery$ContributionPercent <- (Contribution_Summery$AverageContributions / sum(Contribution_Summery$AverageContributions)) * 100
Contribution_Summery <- round(Contribution_Summery, digits = 2)
write.csv(Contribution_Summery, file = "4_Data/OutputData/Plots/24_EMPA/24_EMPA_CH4_Contribution_Summery.csv", row.names = TRUE)
Contribution_Averages_no_bg <- colMeans(EMPA_csv[, c("CH4_energy", "CH4_residential", "CH4_industrial", "CH4_natural_gas", "CH4_transport", "CH4_waste", "CH4_agriculture")])
Contribution_Summery_no_bg <- data.frame(AverageContributions = Contribution_Averages_no_bg)
Contribution_Summery_no_bg$ContributionPercent <- (Contribution_Summery_no_bg$AverageContributions / sum(Contribution_Summery_no_bg$AverageContributions)) * 100
Contribution_Summery_no_bg <- round(Contribution_Summery_no_bg, digits = 2)
write.csv(Contribution_Summery_no_bg, file = "4_Data/OutputData/Plots/24_EMPA/24_EMPA_CH4_Contribution_Summery_no_bg.csv", row.names = TRUE)
